{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e7957e-3064-4330-879a-2e7415d11f94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install --quiet -U ipywidgets langchain langchain-community langchain-core langchainhub tiktoken chromadb pysqlite3-binary sentence-transformers lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc89bc4-53ae-4277-91b8-43fa136208d3",
   "metadata": {},
   "source": [
    "# Set Up The Model\n",
    "In this block, we install chromadb and other dependancies.  Chroma requires sqlite3 so that is imported as well.\n",
    "\n",
    "The LLM that is used is Mistral:Instruct running in Ollama which is hosted in OpenShift.\n",
    "\n",
    "Huggingface Embeddings are used as well and are configured to take advantage of local GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d554fdc-e452-49e7-a6eb-74900cc66b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "import chromadb\n",
    "\n",
    "import os.path\n",
    "import bs4\n",
    "from typing import List\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import BSHTMLLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List\n",
    "\n",
    "model = ChatOllama(model=\"mistral:instruct\",\n",
    "                   base_url=\"http://ollama-api-service.ollama-llm.svc.cluster.local:11434\",\n",
    "                   temperature = 0)\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\",model_kwargs={'device': 'cuda'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc25a114-aa6c-4a5b-a9f8-8397ef8383bf",
   "metadata": {},
   "source": [
    "# Gather Data to Query\n",
    "\n",
    "Let's grab all of the man1 user command pages and load them into the docs variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b47267-2865-4494-a9a4-5da027ed6fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_pages = \"False\"\n",
    "\n",
    "path = 'man7.org/man-pages/man1/index.html.tmp'\n",
    "\n",
    "check_pages = os.path.isfile(path)\n",
    "\n",
    "if check_pages is False:\n",
    "\n",
    "    !wget --quiet -np -r -l1 --cut-dirs=1 -e robots=off --accept-regex [A-Za-z]*.*1.html  -R \"index.html\" https://man7.org/linux/man-pages/man1/ \n",
    "\n",
    "    loader = DirectoryLoader(\n",
    "        \"man7.org/man-pages/man1/\", \n",
    "        glob=\"**/*.html\", \n",
    "        loader_cls=BSHTMLLoader,\n",
    "        show_progress=True,\n",
    "    )\n",
    "    docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04b2832-fa2f-44b0-8b9e-345eca336fff",
   "metadata": {},
   "source": [
    "# Split and Store the data in the vector store\n",
    "\n",
    "First, we delete all of the data in the db folder to ensure that we get a fresh start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a96412-423c-4895-8294-56206d5fc7ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "persist_dir=\"man-db\"\n",
    "\n",
    "check_file = \"False\"\n",
    "\n",
    "path = 'man-db/chroma.sqlite3'\n",
    "\n",
    "check_file = os.path.isfile(path)\n",
    "\n",
    "if check_file or check_pages is False:\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1750, chunk_overlap=100, length_function=len)\n",
    "     \n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    \n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=embedding, persist_directory=\"man-db\")\n",
    "\n",
    "else:\n",
    "    \n",
    "    vectorstore = Chroma(persist_directory=persist_dir, embedding_function=embedding)\n",
    "    \n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c71b422-fc16-4834-b795-ecf4c08f4253",
   "metadata": {},
   "source": [
    "# Run the RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b169560f-ea3b-4b0c-bc48-c08b56525b9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prompt\n",
    "rag_template = \"\"\"\n",
    "Given a question write an answer.\n",
    "Use only the supplied source docs.\n",
    "If you don't know the answer, just say that you don't know.  Do not fake the answer.\n",
    "If the answer is relevant, then ALWAYS include a \"SOURCES\" part in your answer.\n",
    "\n",
    "QUESTION: {question}\n",
    "=========\n",
    "{source_docs}\n",
    "=========\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "\n",
    "def format_docs(docs: List[Document]) -> str:\n",
    "    return \"\\n\\n\".join(\n",
    "        f\"Content: {doc.page_content}\\nSource: {doc.metadata['title']}\" for doc in docs\n",
    "    )\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_template)\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(\n",
    "        source_docs=(lambda x: format_docs(x[\"source_docs\"]))\n",
    "    )\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain = RunnableParallel(\n",
    "    {\n",
    "        \"source_docs\": retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    ").assign(answer=rag_chain_from_docs)\n",
    "\n",
    "question = \"What option for the echo command prevents new lines from being displayed?\"\n",
    "\n",
    "results = (rag_chain.invoke(question))\n",
    "\n",
    "answer = results[\"answer\"]\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9bf7b5-d860-4a9d-bbaa-44bfc577b762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
